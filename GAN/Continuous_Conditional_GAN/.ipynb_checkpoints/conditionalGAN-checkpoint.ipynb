{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data is OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "img_save_path = './conditionalGAN/images/'\n",
    "os.makedirs(img_save_path, exist_ok=True)\n",
    "\n",
    "n_epochs = 2 # number of epochs of training\n",
    "batch_size = 64 # size of the batches\n",
    "lr = 0.0002 # learning rate\n",
    "beta1 = 0.5 # decay of the first order mmomentum of gradient\n",
    "beta2 = 0.999 # decay of second order momentum of gradient\n",
    "latent_dim = 100 # dim of the latent space\n",
    "n_classes = 10 # number of classes for dataset\n",
    "image_size = 28 # size of each image dimension\n",
    "channels = 1 # number of image channels\n",
    "sample_interval = 200 # interval between image sampling\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal(m.weight,0.0,0.02)\n",
    "    elif classname.find('BatchNorm2d')!=-1:\n",
    "        torch.nn.init.normal(m.weight,1.0,0.02)\n",
    "        torch.nn.init.constant(m.bias,0.0)\n",
    "        \n",
    "def idx2onehot(idx, n):\n",
    "    assert torch.max(idx).item() < n and idx.dim() == 1\n",
    "    idx2dim = idx.view(-1,1) # change from 1-dim tensor to 2-dim tensor\n",
    "    onehot = torch.zeros(idx2dim.size(0),n).scatter_(1,idx2dim,1)\n",
    "\n",
    "    return onehot\n",
    "\n",
    "\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1_1 = nn.Linear(latent_dim,256)\n",
    "        self.fc1_1_bn = nn.BatchNorm1d(256)\n",
    "        self.fc1_2 = nn.Linear(10, 256)\n",
    "        self.fc1_2_bn = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.fc2_bn = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512,1024)\n",
    "        self.fc3_bn = nn.BatchNorm1d(1024)\n",
    "        self.fc4 = nn.Linear(1024,image_size**2)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, z, y):\n",
    "        x1 = F.relu(self.fc1_1_bn(self.fc1_1(z)))\n",
    "        x2 = F.relu(self.fc1_2_bn(self.fc1_2(y)))\n",
    "        x = torch.cat([x1, x2], dim = 1)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = F.relu(self.fc3_bn(self.fc3(x)))\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1_1 = nn.Linear(image_size**2, 1024)\n",
    "        self.fc1_2 = nn.Linear(10, 1024)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc2_bn = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512,256)\n",
    "        self.fc3_bn = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "        \n",
    "        # forward method\n",
    "    def forward(self, input, y):\n",
    "        x1 = F.leaky_relu(self.fc1_1(input), 0.2)\n",
    "        x2 = F.leaky_relu(self.fc1_2(y),0.2)\n",
    "        x = torch.cat([x1, x2], dim = 1)\n",
    "        x = F.leaky_relu(self.fc2_bn(self.fc2(x)),0.2)\n",
    "        x = F.leaky_relu(self.fc3_bn(self.fc3(x)),0.2)\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "        \n",
    "# Loss function\n",
    "loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize Generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Move model to the corresponding device\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "# Initialize weights\n",
    "#generator.apply(weights_init_normal)\n",
    "#discriminator.apply(weights_init_normal)\n",
    "\n",
    "data_save_path = './conditionalGAN/data/'\n",
    "os.makedirs(data_save_path, exist_ok = True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*channels,[0.5]*channels)\n",
    "])\n",
    "dataset = datasets.MNIST(root = data_save_path, train = True, download = True, transform=transform)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset,batch_size = batch_size,shuffle=True,drop_last = True)\n",
    "print(\"the data is OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(),lr = lr, betas = (beta1, beta2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(),lr = lr, betas = (beta1, beta2))\n",
    "def reset_grad():\n",
    "    optimizer_D.zero_grad()\n",
    "    optimizer_G.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(n_row, n_col,epoch):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = torch.randn(n_row*n_col, latent_dim).to(device)\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = torch.Tensor([num for _ in range(n_col) for num in range(n_row)]).type(torch.LongTensor)\n",
    "    labels = idx2onehot(labels,n_classes)\n",
    "    gen_imgs = generator(z, labels).view(z.size(0),channels,image_size,image_size) # reshape the output of the generator\n",
    "    save_image(gen_imgs.data, os.path.join(img_save_path,'{}.png'.format(epoch)),nrow=n_row, normalize=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/2], Step [200/937], d_loss: 1.4018, g_loss:0.74, D(G(z)): 0.48\n",
      "Epoch [0/2], Step [400/937], d_loss: 1.4022, g_loss:0.74, D(G(z)): 0.48\n",
      "Epoch [0/2], Step [600/937], d_loss: 1.4001, g_loss:0.74, D(G(z)): 0.48\n",
      "Epoch [0/2], Step [800/937], d_loss: 1.4031, g_loss:0.74, D(G(z)): 0.48\n",
      "Epoch [1/2], Step [200/937], d_loss: 1.3984, g_loss:0.74, D(G(z)): 0.48\n"
     ]
    }
   ],
   "source": [
    "total_step = len(dataloader)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        \n",
    "        real_labels = torch.ones(batch_size,1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size,1).to(device)\n",
    "        \n",
    "        # Configure labels\n",
    "        \n",
    "        labels_onehot = idx2onehot(labels,n_classes).to(device)\n",
    "\n",
    "        \n",
    "        # =============================================\n",
    "        #\n",
    "        #  Training Discriminator \n",
    "        #\n",
    "        # =============================================\n",
    "        \n",
    "        outputs = discriminator(images,labels_onehot)\n",
    "        d_loss_real = loss(outputs, real_labels)\n",
    "        real_score = outputs # just for the purpose of tracking training progress\n",
    "        \n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        label_z = idx2onehot(torch.randint(n_classes,(batch_size,)),n_classes).to(device)\n",
    "        \n",
    "        fake_images = generator(z,label_z).detach()\n",
    "        outputs = discriminator(fake_images,label_z)\n",
    "        d_loss_fake = loss(outputs, fake_labels)\n",
    "        fake_score = outputs # just for the purpose of tracking training progress\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad() # reset stored gradients\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        \n",
    "        # =============================================\n",
    "        #\n",
    "        #  Training Generator\n",
    "        #\n",
    "        # ============================================\n",
    "        \n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        label_z = idx2onehot(torch.randint(n_classes,(batch_size,)),n_classes).to(device)\n",
    "\n",
    "        fake_images = generator(z,label_z)\n",
    "        outputs = discriminator(fake_images,label_z)\n",
    "        g_loss = loss(outputs, real_labels)\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        if (i+1) % sample_interval == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss:{:.2f}, D(G(z)): {:.2f}'.format(epoch, n_epochs, i+1, total_step, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item()))\n",
    "          \n",
    "    sample_image(n_row=10,n_col=10,epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [5, 5],\n",
       "        [9, 9]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(10,[3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
