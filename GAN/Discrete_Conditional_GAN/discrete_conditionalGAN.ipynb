{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data is OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "img_save_path = './conditionalGAN/images/'\n",
    "os.makedirs(img_save_path, exist_ok=True)\n",
    "\n",
    "n_epochs = 200 # number of epochs of training\n",
    "batch_size = 64 # size of the batches\n",
    "lr = 0.0002 # learning rate\n",
    "beta1 = 0.5 # decay of the first order mmomentum of gradient\n",
    "beta2 = 0.999 # decay of second order momentum of gradient\n",
    "latent_dim = 100 # dim of the latent space\n",
    "n_classes = 10 # number of classes for dataset\n",
    "image_size = 28 # size of each image dimension\n",
    "channels = 1 # number of image channels\n",
    "sample_interval = 200 # interval between image sampling\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal(m.weight,0.0,0.02)\n",
    "    elif classname.find('BatchNorm2d')!=-1:\n",
    "        torch.nn.init.normal(m.weight,1.0,0.02)\n",
    "        torch.nn.init.constant(m.bias,0.0)\n",
    "        \n",
    "def idx2onehot(idx, n):\n",
    "    assert torch.max(idx).item() < n and idx.dim() == 1\n",
    "    idx2dim = idx.view(-1,1) # change from 1-dim tensor to 2-dim tensor\n",
    "    onehot = torch.zeros(idx2dim.size(0),n).scatter_(1,idx2dim,1)\n",
    "\n",
    "    return onehot\n",
    "\n",
    "\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1_1 = nn.Linear(latent_dim,256)\n",
    "        self.fc1_1_bn = nn.BatchNorm1d(256)\n",
    "        self.fc1_2 = nn.Linear(10, 256)\n",
    "        self.fc1_2_bn = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.fc2_bn = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512,1024)\n",
    "        self.fc3_bn = nn.BatchNorm1d(1024)\n",
    "        self.fc4 = nn.Linear(1024,image_size**2)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, z, y):\n",
    "        x1 = F.relu(self.fc1_1_bn(self.fc1_1(z)))\n",
    "        x2 = F.relu(self.fc1_2_bn(self.fc1_2(y)))\n",
    "        x = torch.cat([x1, x2], dim = 1)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = F.relu(self.fc3_bn(self.fc3(x)))\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1_1 = nn.Linear(image_size**2, 1024)\n",
    "        self.fc1_2 = nn.Linear(10, 1024)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc2_bn = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512,256)\n",
    "        self.fc3_bn = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "        \n",
    "        # forward method\n",
    "    def forward(self, input, y):\n",
    "        x1 = F.leaky_relu(self.fc1_1(input), 0.2)\n",
    "        x2 = F.leaky_relu(self.fc1_2(y),0.2)\n",
    "        x = torch.cat([x1, x2], dim = 1)\n",
    "        x = F.leaky_relu(self.fc2_bn(self.fc2(x)),0.2)\n",
    "        x = F.leaky_relu(self.fc3_bn(self.fc3(x)),0.2)\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "        \n",
    "# Loss function\n",
    "loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize Generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Move model to the corresponding device\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "# Initialize weights\n",
    "#generator.apply(weights_init_normal)\n",
    "#discriminator.apply(weights_init_normal)\n",
    "\n",
    "data_save_path = './conditionalGAN/data/'\n",
    "os.makedirs(data_save_path, exist_ok = True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*channels,[0.5]*channels)\n",
    "])\n",
    "#\n",
    "dataset = datasets.MNIST(root = data_save_path, train = True, download = True, transform=transform)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset,batch_size = batch_size,shuffle=True,drop_last = True)\n",
    "print(\"the data is OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(),lr = 10*lr, betas = (beta1, beta2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(),lr = lr, betas = (beta1, beta2))\n",
    "def reset_grad():\n",
    "    optimizer_D.zero_grad()\n",
    "    optimizer_G.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(n_row, n_col,epoch):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = torch.randn(n_row*n_col, latent_dim).to(device)\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = torch.Tensor([num for _ in range(n_col) for num in range(n_row)]).type(torch.LongTensor)\n",
    "    labels = idx2onehot(labels,n_classes).to(device)\n",
    "    gen_imgs = generator(z, labels).view(z.size(0),channels,image_size,image_size) # reshape the output of the generator\n",
    "    save_image((((gen_imgs+1)/2).round()-0.5)*2, os.path.join(img_save_path,'{}.png'.format(epoch)),nrow=n_row, normalize=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200], Step [200/937], d_loss: 0.6554, g_loss:1.34, D(x):0.74, D(G(z)): 0.30\n",
      "Epoch [0/200], Step [400/937], d_loss: 1.0590, g_loss:1.31, D(x):0.57, D(G(z)): 0.35\n",
      "Epoch [0/200], Step [600/937], d_loss: 1.1792, g_loss:1.00, D(x):0.60, D(G(z)): 0.46\n",
      "Epoch [0/200], Step [800/937], d_loss: 0.9952, g_loss:1.23, D(x):0.57, D(G(z)): 0.33\n",
      "Epoch [1/200], Step [200/937], d_loss: 1.1205, g_loss:1.39, D(x):0.58, D(G(z)): 0.41\n",
      "Epoch [1/200], Step [400/937], d_loss: 0.8210, g_loss:1.41, D(x):0.74, D(G(z)): 0.40\n",
      "Epoch [1/200], Step [600/937], d_loss: 0.3409, g_loss:2.24, D(x):0.87, D(G(z)): 0.18\n",
      "Epoch [1/200], Step [800/937], d_loss: 0.8184, g_loss:1.48, D(x):0.68, D(G(z)): 0.33\n",
      "Epoch [2/200], Step [200/937], d_loss: 0.6229, g_loss:1.57, D(x):0.77, D(G(z)): 0.27\n",
      "Epoch [2/200], Step [400/937], d_loss: 0.6855, g_loss:1.42, D(x):0.83, D(G(z)): 0.37\n",
      "Epoch [2/200], Step [600/937], d_loss: 0.5985, g_loss:2.10, D(x):0.65, D(G(z)): 0.10\n",
      "Epoch [2/200], Step [800/937], d_loss: 0.3058, g_loss:2.77, D(x):0.87, D(G(z)): 0.15\n",
      "Epoch [3/200], Step [200/937], d_loss: 0.7501, g_loss:1.97, D(x):0.74, D(G(z)): 0.34\n",
      "Epoch [3/200], Step [400/937], d_loss: 0.6389, g_loss:2.03, D(x):0.80, D(G(z)): 0.32\n",
      "Epoch [3/200], Step [600/937], d_loss: 0.6825, g_loss:1.50, D(x):0.66, D(G(z)): 0.20\n",
      "Epoch [3/200], Step [800/937], d_loss: 0.6455, g_loss:1.84, D(x):0.67, D(G(z)): 0.19\n",
      "Epoch [4/200], Step [200/937], d_loss: 0.2743, g_loss:2.11, D(x):0.87, D(G(z)): 0.12\n",
      "Epoch [4/200], Step [400/937], d_loss: 0.4929, g_loss:3.55, D(x):0.93, D(G(z)): 0.32\n",
      "Epoch [4/200], Step [600/937], d_loss: 0.2350, g_loss:3.11, D(x):0.87, D(G(z)): 0.09\n",
      "Epoch [4/200], Step [800/937], d_loss: 0.0811, g_loss:3.06, D(x):0.98, D(G(z)): 0.06\n",
      "Epoch [5/200], Step [200/937], d_loss: 0.1299, g_loss:4.54, D(x):0.91, D(G(z)): 0.03\n",
      "Epoch [5/200], Step [400/937], d_loss: 0.3943, g_loss:1.96, D(x):0.77, D(G(z)): 0.10\n",
      "Epoch [5/200], Step [600/937], d_loss: 1.1555, g_loss:3.23, D(x):0.91, D(G(z)): 0.58\n",
      "Epoch [5/200], Step [800/937], d_loss: 0.4608, g_loss:2.78, D(x):0.79, D(G(z)): 0.18\n",
      "Epoch [6/200], Step [200/937], d_loss: 0.7969, g_loss:1.73, D(x):0.65, D(G(z)): 0.25\n",
      "Epoch [6/200], Step [400/937], d_loss: 0.4708, g_loss:1.96, D(x):0.94, D(G(z)): 0.31\n",
      "Epoch [6/200], Step [600/937], d_loss: 0.1395, g_loss:3.29, D(x):0.95, D(G(z)): 0.08\n",
      "Epoch [6/200], Step [800/937], d_loss: 0.2867, g_loss:2.54, D(x):0.88, D(G(z)): 0.14\n",
      "Epoch [7/200], Step [200/937], d_loss: 0.8771, g_loss:1.93, D(x):0.70, D(G(z)): 0.37\n",
      "Epoch [7/200], Step [400/937], d_loss: 0.4719, g_loss:2.76, D(x):0.87, D(G(z)): 0.26\n",
      "Epoch [7/200], Step [600/937], d_loss: 0.6621, g_loss:0.91, D(x):0.76, D(G(z)): 0.28\n",
      "Epoch [7/200], Step [800/937], d_loss: 0.8359, g_loss:1.96, D(x):0.58, D(G(z)): 0.16\n",
      "Epoch [8/200], Step [200/937], d_loss: 0.8455, g_loss:1.74, D(x):0.64, D(G(z)): 0.28\n",
      "Epoch [8/200], Step [400/937], d_loss: 0.4095, g_loss:1.48, D(x):0.92, D(G(z)): 0.26\n",
      "Epoch [8/200], Step [600/937], d_loss: 1.2519, g_loss:1.19, D(x):0.35, D(G(z)): 0.05\n",
      "Epoch [8/200], Step [800/937], d_loss: 0.5135, g_loss:2.35, D(x):0.69, D(G(z)): 0.10\n",
      "Epoch [9/200], Step [200/937], d_loss: 0.4409, g_loss:3.33, D(x):0.96, D(G(z)): 0.30\n",
      "Epoch [9/200], Step [400/937], d_loss: 0.3555, g_loss:2.87, D(x):0.86, D(G(z)): 0.16\n",
      "Epoch [9/200], Step [600/937], d_loss: 0.2025, g_loss:2.44, D(x):0.89, D(G(z)): 0.07\n",
      "Epoch [9/200], Step [800/937], d_loss: 0.0750, g_loss:3.27, D(x):0.97, D(G(z)): 0.04\n",
      "Epoch [10/200], Step [200/937], d_loss: 0.0434, g_loss:4.29, D(x):0.99, D(G(z)): 0.03\n",
      "Epoch [10/200], Step [400/937], d_loss: 0.0379, g_loss:4.81, D(x):0.99, D(G(z)): 0.03\n",
      "Epoch [10/200], Step [600/937], d_loss: 0.0323, g_loss:4.31, D(x):0.99, D(G(z)): 0.02\n",
      "Epoch [10/200], Step [800/937], d_loss: 0.0092, g_loss:5.99, D(x):1.00, D(G(z)): 0.01\n",
      "Epoch [11/200], Step [200/937], d_loss: 0.0190, g_loss:4.36, D(x):0.99, D(G(z)): 0.01\n",
      "Epoch [11/200], Step [400/937], d_loss: 0.0095, g_loss:5.55, D(x):1.00, D(G(z)): 0.01\n",
      "Epoch [11/200], Step [600/937], d_loss: 0.0100, g_loss:6.69, D(x):1.00, D(G(z)): 0.01\n",
      "Epoch [11/200], Step [800/937], d_loss: 0.0091, g_loss:6.01, D(x):0.99, D(G(z)): 0.00\n",
      "Epoch [12/200], Step [200/937], d_loss: 0.0056, g_loss:6.13, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [12/200], Step [400/937], d_loss: 0.0053, g_loss:7.05, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [12/200], Step [600/937], d_loss: 0.0038, g_loss:5.92, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [12/200], Step [800/937], d_loss: 0.0032, g_loss:6.74, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [13/200], Step [200/937], d_loss: 0.0075, g_loss:7.50, D(x):0.99, D(G(z)): 0.00\n",
      "Epoch [13/200], Step [400/937], d_loss: 0.0018, g_loss:7.99, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [13/200], Step [600/937], d_loss: 0.0032, g_loss:7.91, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [13/200], Step [800/937], d_loss: 0.0007, g_loss:7.83, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [14/200], Step [200/937], d_loss: 0.0011, g_loss:7.44, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [14/200], Step [400/937], d_loss: 0.0015, g_loss:7.37, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [14/200], Step [600/937], d_loss: 0.0008, g_loss:8.13, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [14/200], Step [800/937], d_loss: 0.0007, g_loss:8.05, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [15/200], Step [200/937], d_loss: 0.0012, g_loss:7.71, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [15/200], Step [400/937], d_loss: 0.0013, g_loss:8.00, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [15/200], Step [600/937], d_loss: 0.0006, g_loss:8.39, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [15/200], Step [800/937], d_loss: 0.0012, g_loss:8.52, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [16/200], Step [200/937], d_loss: 0.0007, g_loss:8.57, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [16/200], Step [400/937], d_loss: 3.4859, g_loss:7.21, D(x):0.97, D(G(z)): 0.13\n",
      "Epoch [16/200], Step [600/937], d_loss: 0.0127, g_loss:5.61, D(x):0.99, D(G(z)): 0.01\n",
      "Epoch [16/200], Step [800/937], d_loss: 0.0066, g_loss:5.44, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [17/200], Step [200/937], d_loss: 0.0033, g_loss:5.87, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [17/200], Step [400/937], d_loss: 0.0020, g_loss:7.20, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [17/200], Step [600/937], d_loss: 0.0022, g_loss:7.58, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [17/200], Step [800/937], d_loss: 0.0053, g_loss:6.49, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [18/200], Step [200/937], d_loss: 0.0019, g_loss:6.66, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [18/200], Step [400/937], d_loss: 0.0019, g_loss:7.17, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [18/200], Step [600/937], d_loss: 0.0016, g_loss:7.51, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [18/200], Step [800/937], d_loss: 0.0007, g_loss:7.65, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [19/200], Step [200/937], d_loss: 0.0010, g_loss:7.95, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [19/200], Step [400/937], d_loss: 0.0008, g_loss:8.23, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [19/200], Step [600/937], d_loss: 0.0049, g_loss:6.07, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [19/200], Step [800/937], d_loss: 0.0017, g_loss:6.92, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [20/200], Step [200/937], d_loss: 0.0016, g_loss:7.61, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [20/200], Step [400/937], d_loss: 0.0023, g_loss:7.71, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [20/200], Step [600/937], d_loss: 0.0009, g_loss:8.18, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [20/200], Step [800/937], d_loss: 0.0010, g_loss:7.60, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [21/200], Step [200/937], d_loss: 0.0007, g_loss:7.86, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [21/200], Step [400/937], d_loss: 0.0007, g_loss:8.15, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [21/200], Step [600/937], d_loss: 0.0007, g_loss:8.25, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [21/200], Step [800/937], d_loss: 0.0005, g_loss:8.15, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [22/200], Step [200/937], d_loss: 0.0006, g_loss:8.70, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [22/200], Step [400/937], d_loss: 0.0003, g_loss:8.52, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [22/200], Step [600/937], d_loss: 0.0005, g_loss:9.16, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [22/200], Step [800/937], d_loss: 0.0003, g_loss:10.23, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [23/200], Step [200/937], d_loss: 0.0001, g_loss:8.75, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [23/200], Step [400/937], d_loss: 0.0002, g_loss:10.47, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [23/200], Step [600/937], d_loss: 0.0002, g_loss:9.43, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [23/200], Step [800/937], d_loss: 0.0002, g_loss:9.41, D(x):1.00, D(G(z)): 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200], Step [200/937], d_loss: 0.0031, g_loss:6.58, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [24/200], Step [400/937], d_loss: 0.0015, g_loss:7.48, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [24/200], Step [600/937], d_loss: 0.0014, g_loss:8.52, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [24/200], Step [800/937], d_loss: 0.0010, g_loss:8.50, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [25/200], Step [200/937], d_loss: 0.0006, g_loss:8.60, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [25/200], Step [400/937], d_loss: 0.0006, g_loss:8.88, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [25/200], Step [600/937], d_loss: 0.0004, g_loss:8.67, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [25/200], Step [800/937], d_loss: 0.0006, g_loss:8.83, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [26/200], Step [200/937], d_loss: 0.0005, g_loss:8.12, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [26/200], Step [400/937], d_loss: 0.0002, g_loss:9.19, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [26/200], Step [600/937], d_loss: 0.0011, g_loss:8.43, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [26/200], Step [800/937], d_loss: 0.0006, g_loss:11.20, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [27/200], Step [200/937], d_loss: 0.0002, g_loss:11.04, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [27/200], Step [400/937], d_loss: 0.0003, g_loss:9.97, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [27/200], Step [600/937], d_loss: 0.0001, g_loss:9.34, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [27/200], Step [800/937], d_loss: 0.0001, g_loss:10.26, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [28/200], Step [200/937], d_loss: 0.0002, g_loss:8.82, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [28/200], Step [400/937], d_loss: 0.0001, g_loss:9.44, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [28/200], Step [600/937], d_loss: 0.0001, g_loss:10.02, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [28/200], Step [800/937], d_loss: 0.0003, g_loss:10.22, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [29/200], Step [200/937], d_loss: 0.0001, g_loss:10.99, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [29/200], Step [400/937], d_loss: 0.0001, g_loss:10.77, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [29/200], Step [600/937], d_loss: 0.0005, g_loss:9.76, D(x):1.00, D(G(z)): 0.00\n",
      "Epoch [29/200], Step [800/937], d_loss: 0.0001, g_loss:9.91, D(x):1.00, D(G(z)): 0.00\n"
     ]
    }
   ],
   "source": [
    "total_step = len(dataloader)\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = ((((images.view(images.size(0), -1)+1)/2).round()-0.5)*2).to(device)\n",
    "        \n",
    "        #images = images.view(images.size(0), -1).round().to(device)\n",
    "\n",
    "        real_labels = torch.ones(batch_size,1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size,1).to(device)\n",
    "        \n",
    "        # Configure labels\n",
    "        \n",
    "        labels_onehot = idx2onehot(labels,n_classes).to(device)\n",
    "\n",
    "        \n",
    "        # =============================================\n",
    "        #\n",
    "        #  Training Discriminator \n",
    "        #\n",
    "        # =============================================\n",
    "        \n",
    "        outputs = discriminator(images,labels_onehot)\n",
    "        d_loss_real = loss(outputs, real_labels)\n",
    "        real_score = outputs # just for the purpose of tracking training progress\n",
    "        \n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        label_z = idx2onehot(torch.randint(n_classes,(batch_size,)),n_classes).to(device)\n",
    "        \n",
    "        fake_images = generator(z,label_z).detach()\n",
    "        outputs = discriminator(fake_images,label_z)\n",
    "        d_loss_fake = loss(outputs, fake_labels)\n",
    "        fake_score = outputs # just for the purpose of tracking training progress\n",
    "        # Backprop and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad() # reset stored gradients\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        \n",
    "        # =============================================\n",
    "        #\n",
    "        #  Training Generator\n",
    "        #\n",
    "        # ============================================\n",
    "        \n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        label_z = idx2onehot(torch.randint(n_classes,(batch_size,)),n_classes).to(device)\n",
    "\n",
    "        fake_images = generator(z,label_z)\n",
    "        outputs = discriminator(fake_images,label_z)\n",
    "        g_loss = loss(outputs, real_labels)\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "    \n",
    "        if (i+1) % sample_interval == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss:{:.2f}, D(x):{:.2f}, D(G(z)): {:.2f}'.format(epoch, n_epochs, i+1, total_step, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item()))\n",
    "\n",
    "    sample_image(n_row=10,n_col=10,epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        print(torch.min(images))\n",
    "        shape = images.size()\n",
    "        images = ((((((images.view(images.size(0), -1)+1)/2).round()-0.5)*2)/2+0.5)*255).view(*shape)\n",
    "        plt.imshow(images[0].squeeze().numpy(),cmap='gray')\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
